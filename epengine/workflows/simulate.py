import logging
import re
import shutil
import tempfile
from pathlib import Path

import pandas as pd
from archetypal import IDF
from archetypal.idfclass.sql import Sql
from hatchet_sdk.context import Context

from epengine.hatchet import hatchet
from epengine.models.configs import SimulationSpec
from epengine.utils.results import postprocess, serialize_df_dict

logger = logging.getLogger(__name__)


# TODO: This could be generated by a class method in the SimulationSpec class
# but should it?
@hatchet.workflow(
    name="simulate_epw_idf",
    on_events=["simulation:run_artifacts"],
    timeout="20m",
    version="0.3",
)
class Simulate:
    @hatchet.step(name="simulate", timeout="20m")
    def simulate(self, context: Context):
        data = context.workflow_input()
        data["hcontext"] = context
        spec = SimulationSpec(**data)
        with tempfile.TemporaryDirectory() as tmpdir:
            local_pth = Path(tmpdir) / "model.idf"
            shutil.copy(spec.idf_path, local_pth)
            idf = IDF(local_pth, epw=spec.epw_path)
            if spec.ddy_path:
                add_sizing_design_day(idf, spec.ddy_path)
            context.log(f"Simulating {spec.idf_path}...")
            idf.simulate()

            sql = Sql(idf.sql_file)
            index_data = spec.model_dump(mode="json", exclude_none=True)
            workflow_run_id = context.workflow_run_id()
            # TODO: pull in spawn index
            index_data["workflow_run_id"] = workflow_run_id
            dfs = postprocess(
                sql,
                index_data=index_data,
                tabular_lookups=[("AnnualBuildingUtilityPerformanceSummary", "End Uses")],
                columns=["Electricity", "Natural Gas", "Fuel Oil No 2"],
            )

            # TODO: move these into a separate function
            end_file = idf.simulation_dir / "eplusout.end"
            err_str = end_file.read_text()
            severe_reg = r".*\s(\d+)\sSevere Errors.*"
            warning_reg = r".*\s(\d+)\sWarning.*"
            severe_ct = int(re.match(severe_reg, err_str).groups()[0])
            warning_ct = int(re.match(warning_reg, err_str).groups()[0])

            err_index = pd.MultiIndex.from_tuples([tuple(index_data.values())], names=list(index_data.keys()))
            err_df = pd.DataFrame({"warnings": [warning_ct], "severe": [severe_ct]}, index=err_index)
            dfs["errors"] = err_df

        dfs = serialize_df_dict(dfs)

        return dfs


def add_sizing_design_day(idf: IDF, ddy_file: Path | str):
    """Read ddy file and copy objects over to self.

    Note:
        Will **NOT** add the Rain file to the model
    """
    ddy = IDF(ddy_file, as_version="9.2.0", file_version="9.2.0", prep_outputs=False)
    for objtype, sequence in ddy.idfobjects.items():
        if sequence:
            for obj in sequence:
                if obj.key.upper() in [
                    "SITE:PRECIPITATION",
                    "ROOFIRRIGATION",
                    "SCHEDULE:FILE",
                ] and getattr(obj, "File_Name", "rain").endswith("rain"):
                    continue

                idf.removeallidfobjects(objtype)
                # idf.removeallidfobjects()
                idf.addidfobject(obj)

    del ddy
