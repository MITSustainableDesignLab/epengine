{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from tqdm.asyncio import tqdm as atqdm\n",
    "from tqdm.notebook  import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import httpx\n",
    "\n",
    "root_url = \"https://climate.onebuilding.org\"\n",
    "# configure pool timeouts since max_connections is set to 10 and some requests may take a while\n",
    "pool_timeout = httpx.Timeout(10.0, pool=10800)\n",
    "client = httpx.AsyncClient(base_url=root_url, limits=httpx.Limits(max_connections=10))\n",
    "\n",
    "\n",
    "async def get_subregions(url: str):\n",
    "    res = await client.get(url)\n",
    "    soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "    # get any a tags which are in td tags\n",
    "    tags = soup.find_all(\"td\")\n",
    "    regions = []\n",
    "    for tag in tags:\n",
    "        a = tag.find(\"a\")\n",
    "        if a:\n",
    "            if a[\"href\"].endswith(\"html\"):\n",
    "                child_region = Path(url).parent / a[\"href\"]\n",
    "                regions.append(child_region.as_posix())\n",
    "\n",
    "    return regions\n",
    "\n",
    "\n",
    "async def get_file_list(url: str):\n",
    "    res = await client.get(url)\n",
    "    soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "    # get the table element with class \"file-table\"\n",
    "    table = soup.find(\"table\", summary=\"file table\")\n",
    "    a_tags = table.find_all(\"a\", href=re.compile(r\".*\\.zip\"))\n",
    "    urls = []\n",
    "    for tag in a_tags:\n",
    "        resource_url: Path = Path(url).parent / tag[\"href\"]\n",
    "        urls.append(resource_url.as_posix())\n",
    "    return urls\n",
    "\n",
    "\n",
    "output_dir = Path(\"D:/onebuilding\")\n",
    "\n",
    "    \n",
    "def make_row_dict(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        epw = f.readline()\n",
    "    data = epw.split(\",\")\n",
    "    city = data[1]\n",
    "    province = data[2]\n",
    "    country = data[3]\n",
    "    lat = float(data[-4])\n",
    "    lon = float(data[-3])\n",
    "    location = f\"POINT({lon} {lat})\"\n",
    "    tz =(float(data[-2]))\n",
    "    file_path = Path(path)\n",
    "    name = file_path.stem\n",
    "    is_tmy3 = \"tmy3\" in name.lower()\n",
    "    is_tmyx = \"tmyx\" in name.lower()\n",
    "    wmo = re.compile(r\".*\\.(\\d{6})\").match(name).group(1) if re.compile(r\".*\\.(\\d{6})\").match(name) else None\n",
    "    year_pattern = r\"(?<![0-9])(?:20|19)\\d{2}(?![0-9])\"\n",
    "    applicable_years = re.findall(year_pattern, name)\n",
    "    start_year = int(applicable_years[0]) if len(applicable_years) == 2 else None\n",
    "    end_year = int(applicable_years[1]) if len(applicable_years) == 2 else None\n",
    "    year = int(applicable_years[0]) if len(applicable_years) == 1 else None\n",
    "    \n",
    "    data = {\n",
    "        \"name\": name,\n",
    "        \"location\": location,\n",
    "        \"path\": path,\n",
    "        \"country\": country,\n",
    "        \"province\": province,\n",
    "        \"city\": city,\n",
    "        \"lat\": lat,\n",
    "        \"lon\": lon,\n",
    "        \"wmo\": wmo,\n",
    "        \"tz\": tz,\n",
    "        \"TM3\": is_tmy3,\n",
    "        \"TMx\": is_tmyx,\n",
    "        \"year\": year,\n",
    "        \"start_year\": start_year,\n",
    "        \"end_year\": end_year,\n",
    "    }\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "async def download_zip_and_unzip(file):\n",
    "    out_zip = output_dir / Path(file)\n",
    "    out_folder = out_zip.parent / out_zip.stem\n",
    "    out_epw = out_folder / f\"{out_zip.stem}.epw\"\n",
    "    if not (out_epw).exists():\n",
    "        out_zip.parent.mkdir(parents=True, exist_ok=True)\n",
    "        try:\n",
    "            res = await client.get(file)\n",
    "        except Exception as e:\n",
    "            return (-1, e)\n",
    "        try:\n",
    "            with open(out_zip, \"wb\") as f:\n",
    "                f.write(res.content)\n",
    "            out_folder.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.unpack_archive(out_zip, out_folder)\n",
    "            out_zip.unlink()\n",
    "\n",
    "        except Exception as e:\n",
    "            out_zip.unlink(missing_ok=True)\n",
    "            shutil.rmtree(out_folder)\n",
    "            return (-2, e)\n",
    "    else:\n",
    "        await asyncio.sleep(0.01)\n",
    "    return (0, out_epw)\n",
    "    try:\n",
    "        data = make_row_dict(out_epw)\n",
    "        data[\"file\"] = file\n",
    "        return (0, data)\n",
    "    except Exception as e:\n",
    "        return (-3, e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch = False\n",
    "if fetch:\n",
    "    home = await client.get(\"/default.html\")\n",
    "    soup = BeautifulSoup(home.content, \"html.parser\")\n",
    "    # find all a tags with hrefs that start with \"WMO_REGION_\"\n",
    "    regions = list({a[\"href\"] for a in soup.find_all(\"a\", href=re.compile(r\"WMO_Region_\"))})\n",
    "    subregion_promises = [get_subregions(region) for region in regions]\n",
    "    subregions = [r for region in await atqdm.gather(*subregion_promises) for r in region]\n",
    "    file_promises = [get_file_list(subregion) for subregion in subregions]\n",
    "    files = [f for subregion in await atqdm.gather(*file_promises) for f in subregion]\n",
    "    with open(\"paths.json\", 'w') as f:\n",
    "        json.dump(files, f)\n",
    "else:\n",
    "    with open(\"paths.json\", 'r') as f:\n",
    "        files = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde931947d8a437c9efe220b1c51100d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 988, Other: 12\n",
      "Errors: 0, Pulled: 993, Other: 7\n",
      "Errors: 0, Pulled: 990, Other: 10\n",
      "Errors: 0, Pulled: 987, Other: 13\n",
      "Errors: 0, Pulled: 982, Other: 18\n",
      "Errors: 0, Pulled: 996, Other: 4\n",
      "Errors: 0, Pulled: 990, Other: 10\n",
      "Errors: 0, Pulled: 982, Other: 18\n",
      "Errors: 1, Pulled: 997, Other: 2\n",
      "Errors: 1, Pulled: 995, Other: 4\n",
      "Errors: 0, Pulled: 988, Other: 12\n",
      "Errors: 0, Pulled: 997, Other: 3\n",
      "Errors: 0, Pulled: 988, Other: 12\n",
      "Errors: 1, Pulled: 991, Other: 8\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 45, Pulled: 945, Other: 10\n",
      "Errors: 0, Pulled: 997, Other: 3\n",
      "Errors: 0, Pulled: 997, Other: 3\n",
      "Errors: 0, Pulled: 997, Other: 3\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 998, Other: 2\n",
      "Errors: 0, Pulled: 999, Other: 1\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 16, Pulled: 973, Other: 11\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 9, Pulled: 991, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 1, Pulled: 999, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 33, Pulled: 967, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 149, Pulled: 851, Other: 0\n",
      "Errors: 8, Pulled: 992, Other: 0\n",
      "Errors: 39, Pulled: 961, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 45, Pulled: 955, Other: 0\n",
      "Errors: 26, Pulled: 974, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 15, Pulled: 985, Other: 0\n",
      "Errors: 1, Pulled: 999, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 1000, Other: 0\n",
      "Errors: 0, Pulled: 361, Other: 0\n"
     ]
    }
   ],
   "source": [
    "hop_size = 1000\n",
    "all_exit_codes = []\n",
    "for ix in tqdm(range(0, len(files), hop_size)):\n",
    "    exit_codes = [e for e in await asyncio.gather(*[download_zip_and_unzip(file) for file in files[ix:ix+hop_size]])]\n",
    "    all_exit_codes.extend(exit_codes)\n",
    "    errors_fetching = len([e for e in exit_codes if e[0] == -1])\n",
    "    pulled = len([e for e in exit_codes if e[0] == 0])\n",
    "    other = len([e for e in exit_codes if e[0] != 0 and e[0] != -1])\n",
    "    print(f\"Errors: {errors_fetching}, Pulled: {pulled}, Other: {other}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for e in all_exit_codes:\n",
    "    if e[0] != 0:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a507d0f4cf4a487180a83c7ce8f9cf0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86361 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_rows = []\n",
    "for i,e in tqdm(enumerate(all_exit_codes), total=len(all_exit_codes)):\n",
    "    if e[0] == 0:\n",
    "        try:\n",
    "            all_rows.append(make_row_dict(e[1]))\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    if i % 1000:\n",
    "        df = pd.DataFrame(all_rows)\n",
    "        # df.to_csv(\"epw_metadata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"epw_metadata_wkt.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
